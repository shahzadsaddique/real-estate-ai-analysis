"""
Analysis data models.

This module defines Pydantic models for property analysis results
generated by LLM orchestration.
"""

from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field


class AnalysisStatus(str, Enum):
    """Analysis processing status enum."""

    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETE = "complete"
    FAILED = "failed"


class PropertyAnalysis(BaseModel):
    """Property analysis result model."""

    property_address: Optional[str] = Field(None, description="Property address")
    property_type: Optional[str] = Field(None, description="Type of property")
    zoning_classification: Optional[str] = Field(
        None, description="Zoning classification"
    )
    zoning_summary: Optional[str] = Field(None, description="Summary of zoning regulations")
    risk_assessment: Optional[Dict[str, Any]] = Field(
        None, description="Risk assessment details"
    )
    permit_requirements: Optional[List[str]] = Field(
        None, description="List of permit requirements"
    )
    restrictions: Optional[List[str]] = Field(
        None, description="List of property restrictions"
    )
    recommendations: Optional[List[str]] = Field(
        None, description="List of recommendations"
    )
    key_findings: Optional[List[str]] = Field(
        None, description="Key findings from analysis"
    )
    compliance_status: Optional[str] = Field(
        None, description="Overall compliance status"
    )
    additional_insights: Optional[Dict[str, Any]] = Field(
        None, description="Additional insights and data"
    )

    class Config:
        json_schema_extra = {
            "example": {
                "property_address": "123 Main St, City, State 12345",
                "property_type": "Residential",
                "zoning_classification": "R-1",
                "zoning_summary": "Single-family residential zone with specific height restrictions",
                "risk_assessment": {
                    "flood_risk": "Low",
                    "fire_risk": "Medium",
                },
                "permit_requirements": [
                    "Building permit required for new construction",
                    "Zoning variance needed for accessory structure",
                ],
                "restrictions": [
                    "Maximum building height: 35 feet",
                    "Setback requirements: 25 feet front, 10 feet side",
                ],
                "recommendations": [
                    "Consult with zoning board before major renovations",
                    "Consider flood insurance given location",
                ],
                "key_findings": [
                    "Property is in compliance with current zoning",
                    "No major restrictions identified",
                ],
                "compliance_status": "Compliant",
            }
        }


class AnalysisResult(BaseModel):
    """Analysis result container model."""

    analysis: PropertyAnalysis = Field(..., description="Property analysis data")
    source_documents: List[str] = Field(
        ..., description="List of document IDs used in analysis"
    )
    confidence_score: Optional[float] = Field(
        None, description="Confidence score (0-1)", ge=0.0, le=1.0
    )
    processing_time_seconds: Optional[float] = Field(
        None, description="Time taken to generate analysis", ge=0.0
    )
    llm_model: Optional[str] = Field(None, description="LLM model used for analysis")
    tokens_used: Optional[int] = Field(None, description="Number of tokens used", ge=0)
    chunks_retrieved: Optional[int] = Field(
        None, description="Number of chunks retrieved for analysis", ge=0
    )

    class Config:
        json_schema_extra = {
            "example": {
                "analysis": {
                    "property_address": "123 Main St",
                    "zoning_classification": "R-1",
                },
                "source_documents": ["doc_123", "doc_456"],
                "confidence_score": 0.95,
                "processing_time_seconds": 12.5,
                "llm_model": "gemini-2.5-pro",
                "tokens_used": 5000,
                "chunks_retrieved": 15,
            }
        }


class Analysis(BaseModel):
    """Analysis model representing a complete analysis record."""

    id: str = Field(..., description="Unique analysis identifier")
    document_id: str = Field(..., description="Document ID this analysis is for")
    status: AnalysisStatus = Field(
        default=AnalysisStatus.PENDING, description="Current analysis status"
    )
    result: Optional[AnalysisResult] = Field(
        None, description="Analysis result data"
    )
    created_at: datetime = Field(
        default_factory=lambda: datetime.utcnow(), description="Creation timestamp"
    )
    updated_at: datetime = Field(
        default_factory=lambda: datetime.utcnow(), description="Last update timestamp"
    )
    started_at: Optional[datetime] = Field(
        None, description="When analysis started"
    )
    completed_at: Optional[datetime] = Field(
        None, description="When analysis completed"
    )
    error_message: Optional[str] = Field(None, description="Error message if failed")
    retry_count: int = Field(default=0, description="Number of retry attempts", ge=0)

    def model_dump_for_firestore(self) -> dict:
        """Serialize model for Firestore (convert datetime to ISO strings)."""
        data = self.model_dump()
        data["created_at"] = self.created_at.isoformat()
        data["updated_at"] = self.updated_at.isoformat()
        if self.started_at:
            data["started_at"] = self.started_at.isoformat()
        if self.completed_at:
            data["completed_at"] = self.completed_at.isoformat()
        return data

    @classmethod
    def from_firestore(cls, analysis_id: str, data: dict) -> "Analysis":
        """Create Analysis instance from Firestore data."""
        # Parse datetime strings back to datetime objects
        if "created_at" in data and isinstance(data["created_at"], str):
            data["created_at"] = datetime.fromisoformat(data["created_at"])
        if "updated_at" in data and isinstance(data["updated_at"], str):
            data["updated_at"] = datetime.fromisoformat(data["updated_at"])
        if "started_at" in data and data["started_at"]:
            if isinstance(data["started_at"], str):
                data["started_at"] = datetime.fromisoformat(data["started_at"])
        if "completed_at" in data and data["completed_at"]:
            if isinstance(data["completed_at"], str):
                data["completed_at"] = datetime.fromisoformat(data["completed_at"])

        data["id"] = analysis_id
        return cls(**data)

    class Config:
        json_schema_extra = {
            "example": {
                "id": "analysis_123456",
                "document_id": "doc_123456",
                "status": "complete",
                "result": {
                    "analysis": {
                        "property_address": "123 Main St",
                        "zoning_classification": "R-1",
                    },
                    "source_documents": ["doc_123456"],
                },
                "created_at": "2024-01-01T00:00:00Z",
                "updated_at": "2024-01-01T00:00:00Z",
            }
        }
